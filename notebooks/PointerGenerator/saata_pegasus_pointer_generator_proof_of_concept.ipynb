{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import & Setup"
      ],
      "metadata": {
        "id": "bN-EKLRDOppJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwO5Nk66aZsa",
        "outputId": "c4836308-7eac-4ba8-a3f4-747e573c44b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 78.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 67.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.3.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=09dd782d1d31bb663e370c50d19fdd7501e2f60d93d76a1af9737dae2886f04f\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, sentencepiece, rouge-score, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 rouge-score-0.1.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers rouge-score nltk sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from datasets import load_metric, Dataset\n",
        "import datasets\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import sentencepiece as spm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efA88SoQargI",
        "outputId": "257cb23a-18e8-4eb2-cc04-781c4f77eddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "C87fuIxxg-wG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0a2b23-c3aa-4a95-a400-a6048df854fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "P3EWH6tiO1tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "NmB2IRv3biXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data = pd.read_csv(io.BytesIO(uploaded['arxiv_data_210930-054931.csv']))\n",
        "#data"
      ],
      "metadata": {
        "id": "6-6oPfxvbpA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Data Science/UCB Master of Information and Data Science (MIDS)/MIDS W266 Natural Language Processing with Deep Learning/summarizing_abstract/data/raw/arxiv_data_210930-054931.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "dIOK3sjoZfWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f51d2c74-bdc8-49ec-af7b-0e4c593176a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             terms  \\\n",
              "0                                        ['cs.LG']   \n",
              "1                               ['cs.LG', 'cs.AI']   \n",
              "2                    ['cs.LG', 'cs.CR', 'stat.ML']   \n",
              "3                               ['cs.LG', 'cs.CR']   \n",
              "4                                        ['cs.LG']   \n",
              "...                                            ...   \n",
              "56176                           ['cs.CV', 'cs.IR']   \n",
              "56177  ['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']   \n",
              "56178                                    ['cs.LG']   \n",
              "56179              ['stat.ML', 'cs.LG', 'math.OC']   \n",
              "56180                ['cs.LG', 'cs.AI', 'stat.ML']   \n",
              "\n",
              "                                                  titles  \\\n",
              "0      Multi-Level Attention Pooling for Graph Neural...   \n",
              "1      Decision Forests vs. Deep Networks: Conceptual...   \n",
              "2      Power up! Robust Graph Convolutional Network v...   \n",
              "3      Releasing Graph Neural Networks with Different...   \n",
              "4      Recurrence-Aware Long-Term Cognitive Network f...   \n",
              "...                                                  ...   \n",
              "56176  Mining Spatio-temporal Data on Industrializati...   \n",
              "56177  Wav2Letter: an End-to-End ConvNet-based Speech...   \n",
              "56178  Deep Reinforcement Learning with Double Q-lear...   \n",
              "56179                        Generalized Low Rank Models   \n",
              "56180  Chi-square Tests Driven Method for Learning th...   \n",
              "\n",
              "                                               abstracts  \n",
              "0      Graph neural networks (GNNs) have been widely ...  \n",
              "1      Deep networks and decision forests (such as ra...  \n",
              "2      Graph convolutional networks (GCNs) are powerf...  \n",
              "3      With the increasing popularity of Graph Neural...  \n",
              "4      Machine learning solutions for pattern classif...  \n",
              "...                                                  ...  \n",
              "56176  Despite the growing availability of big data i...  \n",
              "56177  This paper presents a simple end-to-end model ...  \n",
              "56178  The popular Q-learning algorithm is known to o...  \n",
              "56179  Principal components analysis (PCA) is a well-...  \n",
              "56180  SDYNA is a general framework designed to addre...  \n",
              "\n",
              "[56181 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fa16062-ada3-43c9-ad36-59ad8bb5a9d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>terms</th>\n",
              "      <th>titles</th>\n",
              "      <th>abstracts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['cs.LG']</td>\n",
              "      <td>Multi-Level Attention Pooling for Graph Neural...</td>\n",
              "      <td>Graph neural networks (GNNs) have been widely ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['cs.LG', 'cs.AI']</td>\n",
              "      <td>Decision Forests vs. Deep Networks: Conceptual...</td>\n",
              "      <td>Deep networks and decision forests (such as ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['cs.LG', 'cs.CR', 'stat.ML']</td>\n",
              "      <td>Power up! Robust Graph Convolutional Network v...</td>\n",
              "      <td>Graph convolutional networks (GCNs) are powerf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['cs.LG', 'cs.CR']</td>\n",
              "      <td>Releasing Graph Neural Networks with Different...</td>\n",
              "      <td>With the increasing popularity of Graph Neural...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['cs.LG']</td>\n",
              "      <td>Recurrence-Aware Long-Term Cognitive Network f...</td>\n",
              "      <td>Machine learning solutions for pattern classif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56176</th>\n",
              "      <td>['cs.CV', 'cs.IR']</td>\n",
              "      <td>Mining Spatio-temporal Data on Industrializati...</td>\n",
              "      <td>Despite the growing availability of big data i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56177</th>\n",
              "      <td>['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']</td>\n",
              "      <td>Wav2Letter: an End-to-End ConvNet-based Speech...</td>\n",
              "      <td>This paper presents a simple end-to-end model ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56178</th>\n",
              "      <td>['cs.LG']</td>\n",
              "      <td>Deep Reinforcement Learning with Double Q-lear...</td>\n",
              "      <td>The popular Q-learning algorithm is known to o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56179</th>\n",
              "      <td>['stat.ML', 'cs.LG', 'math.OC']</td>\n",
              "      <td>Generalized Low Rank Models</td>\n",
              "      <td>Principal components analysis (PCA) is a well-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56180</th>\n",
              "      <td>['cs.LG', 'cs.AI', 'stat.ML']</td>\n",
              "      <td>Chi-square Tests Driven Method for Learning th...</td>\n",
              "      <td>SDYNA is a general framework designed to addre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56181 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fa16062-ada3-43c9-ad36-59ad8bb5a9d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4fa16062-ada3-43c9-ad36-59ad8bb5a9d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4fa16062-ada3-43c9-ad36-59ad8bb5a9d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = Dataset.from_pandas(data)\n",
        "datasets"
      ],
      "metadata": {
        "id": "qqEGQVqjbueA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cfb8c8b-7f48-4c5f-9656-825b4d06b687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['terms', 'titles', 'abstracts'],\n",
              "    num_rows: 56181\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Validation/Test Split"
      ],
      "metadata": {
        "id": "qgQ5WsQBO-E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, validation_dataset = datasets.train_test_split(test_size=0.1).values()"
      ],
      "metadata": {
        "id": "qPVUceyacEl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = train_dataset.train_test_split(test_size=0.1).values()"
      ],
      "metadata": {
        "id": "ADwOs-nacL1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "datasets = datasets.DatasetDict({\"train\":train_dataset,\"test\":test_dataset, \"validation\":validation_dataset})\n",
        "datasets"
      ],
      "metadata": {
        "id": "0uUyjc75cVSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc0dda5-ce8a-4afd-c57e-6b1bd5534d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['terms', 'titles', 'abstracts'],\n",
              "        num_rows: 45505\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['terms', 'titles', 'abstracts'],\n",
              "        num_rows: 5057\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['terms', 'titles', 'abstracts'],\n",
              "        num_rows: 5619\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets[\"train\"] = datasets[\"train\"].shuffle().select(range(20000))\n",
        "datasets[\"validation\"] = datasets[\"validation\"].shuffle().select(range(2000))\n",
        "datasets[\"test\"] = datasets[\"test\"].shuffle().select(range(2000))"
      ],
      "metadata": {
        "id": "KRtwIwAxcY5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model from G-Drive"
      ],
      "metadata": {
        "id": "iN-WX4u9PbpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"pegasus-saata-baseline\"\n",
        "model_dir = f\"drive/MyDrive/Models/{model_name}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
        "\n",
        "max_input_length = 512"
      ],
      "metadata": {
        "id": "ZGlebkafkccf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Pointer Generator (TPG) Model Proof-of-concept"
      ],
      "metadata": {
        "id": "bf5arlF0VlH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To address this potential issue, we propose a novel variant of the original pointer-generator network architecture, *TPG (transformer point-er-generator)* model, to enable the model to copy words from the source input text via *pointing*, which we expect to improve the per-formance of text summarization tasks of our baseline fine-tuned seq2seq models.\n",
        "\n",
        "The proposed hybrid pointer-generator network architecture combines the vocabulary distributions (prediction output) and multi-head cross attention distributions generated from a pre-trained text summarization seq2seq transformer models (i.e., BART, PEGASUS, T5) to predict the generation probability for each decoder timestep $p_{gen}∈ [0,1]$ . The probability $p_{gen}$ for timestep $t$ is calculated from the context vector $h^*_t$, the decoder state $s_t$ and the decoder input $x_t$:\n",
        "\n",
        "$p_{gen}=σ(w_h^T*h_t^*+w_s^T*s_t+w_x^T*x_t+b_ptr )$\n",
        "\n",
        "where vectors $w_h$ , $w_s$, $w_x$ and scalar $b_ptr$ are learnable parameters and σ is the sigmoid function"
      ],
      "metadata": {
        "id": "RFli9NrvuZSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"attachment:TPG_transformer_pointer_generator_network_revised.jpg\" width=\"500\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "QSc30NXVusQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can extract context vector $h^*_t$, the decoder state $s_t$ and the decoder input $x_t$ from the pretrained fine-tuned PEGASUS model:"
      ],
      "metadata": {
        "id": "SQNFvMq4uyzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ncLyke3F4VC",
        "outputId": "a26d9301-eb2f-436b-9356-718e06fec908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PegasusForConditionalGeneration(\n",
            "  (model): PegasusModel(\n",
            "    (shared): Embedding(96103, 1024, padding_idx=0)\n",
            "    (encoder): PegasusEncoder(\n",
            "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
            "      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n",
            "      (layers): ModuleList(\n",
            "        (0): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (6): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (7): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (8): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (9): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (10): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (11): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (12): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (13): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (14): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (15): PegasusEncoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): PegasusDecoder(\n",
            "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
            "      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n",
            "      (layers): ModuleList(\n",
            "        (0): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (6): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (7): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (8): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (9): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (10): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (11): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (12): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (13): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (14): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (15): PegasusDecoderLayer(\n",
            "          (self_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): PegasusAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a test example, we can extract the transformer hidden states and encoder-decoder cross-attention by the `PegasusForConditionalGeneration.forward()` method."
      ],
      "metadata": {
        "id": "2y3xH3mTu8Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abstract = datasets['test']['abstracts'][0]\n",
        "inputs = [\"summarize: \" + abstract]\n",
        "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
        "decoder_inputs = tokenizer(\"\", return_tensors=\"pt\")\n",
        "outputs = model.forward(input_ids=inputs.input_ids,\n",
        "                        attention_mask=inputs.attention_mask,\n",
        "                        decoder_input_ids=decoder_inputs.input_ids,\n",
        "                        output_hidden_states=True,\n",
        "                        output_attentions=True)"
      ],
      "metadata": {
        "id": "3aitf1KNb9i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6BasWJLFd6f",
        "outputId": "f791fc5c-aad1-4470-8528-248b65c1aa05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the past decade the mathematical theory of machine learning has lagged far\r\n",
            "behind the triumphs of deep neural networks on practical challenges. However,\r\n",
            "the gap between theory and practice is gradually starting to close. In this\r\n",
            "paper I will attempt to assemble some pieces of the remarkable and still\r\n",
            "incomplete mathematical mosaic emerging from the efforts to understand the\r\n",
            "foundations of deep learning. The two key themes will be interpolation, and its\r\n",
            "sibling, over-parameterization. Interpolation corresponds to fitting data, even\r\n",
            "noisy data, exactly. Over-parameterization enables interpolation and provides\r\n",
            "flexibility to select a right interpolating model.\r\n",
            "  As we will see, just as a physical prism separates colors mixed within a ray\r\n",
            "of light, the figurative prism of interpolation helps to disentangle\r\n",
            "generalization and optimization properties within the complex picture of modern\r\n",
            "Machine Learning. This article is written with belief and hope that clearer\r\n",
            "understanding of these issues brings us a step closer toward a general theory\r\n",
            "of deep learning and machine learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary Distribution:\")\n",
        "print(outputs.decoder_hidden_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkvI6eNUY3lp",
        "outputId": "5eb38304-e72d-4640-f1e7-374c2a8af1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Distribution:\n",
            "(tensor([[[-1.8576e+01, -7.7758e-03,  5.4886e+01,  ..., -3.9867e+00,\n",
            "           1.2295e+01, -2.6963e+00]]], grad_fn=<AddBackward0>), tensor([[[-10.0656, -12.6732,  34.3188,  ...,  -6.6054,   7.9227,  -7.4615]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[10.0759,  4.1235, 53.9034,  ...,  6.6956,  1.8556,  3.8106]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[  0.2483,   5.4233,  55.6269,  ..., -16.7475, -23.3910,  32.6636]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[ 56.6540, -41.3813,  72.5320,  ...,   6.7152, -32.4193,  58.9642]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[101.8255,   8.6658, 117.4852,  ...,  14.5300,   1.6791,  58.7417]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[112.8141, -25.6616, 111.3830,  ...,  51.0570,   6.7364,  91.6880]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[115.7590, -34.1688, 114.0858,  ...,  47.8927,  10.8204, 149.2177]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[ 91.7853, -61.0717, 101.2149,  ...,  52.6648, -39.4530, 116.6382]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[128.3522, -91.7972, 139.4756,  ...,  63.5999, -71.8244, 129.9750]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[ 41.2471, -47.7205, 105.5437,  ..., -18.3716, -54.0403, 123.3063]]],\n",
            "       grad_fn=<AddBackward0>), tensor([[[  21.3125, -113.1596,  165.8983,  ...,   27.7522,  -63.3740,\n",
            "            69.0181]]], grad_fn=<AddBackward0>), tensor([[[-117.9488, -108.8655,  191.1263,  ...,    5.6292,  -84.1012,\n",
            "            22.0054]]], grad_fn=<AddBackward0>), tensor([[[-258.1758,  -95.0093,  206.3090,  ...,    4.8483,   34.6171,\n",
            "           -62.0746]]], grad_fn=<AddBackward0>), tensor([[[-257.9626,   45.0206,  205.8330,  ..., -114.0329,   15.9406,\n",
            "            -6.8083]]], grad_fn=<AddBackward0>), tensor([[[-272.5239,  137.2579,  195.3377,  ..., -171.7495, -177.4350,\n",
            "           -85.6988]]], grad_fn=<AddBackward0>), tensor([[[-0.1768, -0.0050,  0.2316,  ..., -0.1031, -0.0421, -0.0165]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Attention Distribution:\")\n",
        "print(outputs.cross_attentions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJCJO7JoY5f2",
        "outputId": "670bd658-ea03-4581-f9e9-32d8446e3d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Distribution:\n",
            "(tensor([[[[3.7598e-04, 6.3400e-03, 1.4692e-04,  ..., 9.7645e-05,\n",
            "           2.9446e-04, 1.9355e-03]],\n",
            "\n",
            "         [[2.3703e-06, 5.5529e-04, 4.5900e-05,  ..., 7.6131e-06,\n",
            "           2.3455e-03, 5.1132e-03]],\n",
            "\n",
            "         [[1.4488e-03, 2.8840e-03, 1.7712e-03,  ..., 4.4406e-04,\n",
            "           9.1826e-04, 5.7548e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[3.5904e-03, 5.6379e-03, 9.0207e-04,  ..., 2.4047e-04,\n",
            "           4.2404e-04, 4.8209e-04]],\n",
            "\n",
            "         [[3.0275e-03, 1.0120e-02, 3.3006e-03,  ..., 1.0809e-03,\n",
            "           6.3440e-03, 3.4218e-02]],\n",
            "\n",
            "         [[9.7725e-04, 7.2858e-03, 7.7255e-04,  ..., 2.1925e-05,\n",
            "           8.1245e-04, 7.6313e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[1.2403e-06, 7.4732e-04, 2.7157e-05,  ..., 5.9382e-04,\n",
            "           3.7734e-04, 1.7455e-03]],\n",
            "\n",
            "         [[1.3258e-03, 2.1206e-03, 6.6782e-04,  ..., 1.7513e-03,\n",
            "           8.2910e-03, 1.9901e-02]],\n",
            "\n",
            "         [[2.0986e-04, 6.2689e-03, 2.0640e-04,  ..., 3.1721e-04,\n",
            "           1.4198e-02, 4.7888e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[6.3349e-04, 2.7495e-03, 4.2546e-04,  ..., 5.7598e-04,\n",
            "           3.8983e-03, 3.6428e-04]],\n",
            "\n",
            "         [[4.7890e-04, 6.4223e-03, 5.9022e-04,  ..., 5.3157e-04,\n",
            "           7.8192e-04, 2.8309e-03]],\n",
            "\n",
            "         [[1.3578e-03, 3.4321e-02, 3.8822e-03,  ..., 1.0154e-03,\n",
            "           8.9686e-03, 8.9075e-02]]]], grad_fn=<ViewBackward0>), tensor([[[[4.4969e-04, 3.2483e-03, 6.1930e-04,  ..., 6.9767e-04,\n",
            "           2.7267e-03, 1.7751e-03]],\n",
            "\n",
            "         [[4.8381e-04, 2.2635e-03, 3.3232e-03,  ..., 6.4871e-04,\n",
            "           1.7548e-03, 5.7152e-04]],\n",
            "\n",
            "         [[9.2194e-05, 4.1151e-03, 2.2754e-04,  ..., 3.6169e-05,\n",
            "           1.0763e-04, 5.9240e-08]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[5.3704e-04, 2.3516e-03, 1.3916e-03,  ..., 1.1467e-03,\n",
            "           2.5566e-04, 2.3513e-04]],\n",
            "\n",
            "         [[2.3009e-04, 3.3458e-03, 1.9051e-03,  ..., 4.2360e-05,\n",
            "           1.7846e-03, 2.2979e-04]],\n",
            "\n",
            "         [[7.9144e-05, 1.2832e-03, 3.0131e-04,  ..., 4.4634e-05,\n",
            "           2.7951e-03, 1.1854e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[9.7536e-04, 9.3114e-03, 3.3553e-03,  ..., 3.4008e-04,\n",
            "           7.1886e-03, 6.1233e-03]],\n",
            "\n",
            "         [[7.9283e-04, 2.0087e-03, 7.5439e-04,  ..., 1.8655e-04,\n",
            "           2.2302e-03, 4.9845e-03]],\n",
            "\n",
            "         [[2.3577e-03, 7.4999e-03, 7.8418e-05,  ..., 1.3604e-03,\n",
            "           3.2239e-03, 1.4202e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.2792e-02, 3.5104e-02, 3.7369e-04,  ..., 7.5471e-04,\n",
            "           2.2463e-03, 3.9731e-03]],\n",
            "\n",
            "         [[1.1019e-02, 3.8467e-02, 2.1968e-03,  ..., 1.9334e-03,\n",
            "           3.2408e-03, 1.9158e-02]],\n",
            "\n",
            "         [[2.2536e-02, 1.1434e-02, 1.6923e-03,  ..., 4.6867e-04,\n",
            "           2.5178e-03, 5.0804e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[3.4666e-05, 8.7004e-04, 4.4587e-05,  ..., 3.8416e-05,\n",
            "           2.4043e-04, 2.6319e-04]],\n",
            "\n",
            "         [[1.1496e-04, 1.5588e-03, 2.2770e-04,  ..., 1.3485e-05,\n",
            "           1.8047e-03, 1.4961e-03]],\n",
            "\n",
            "         [[8.8146e-04, 8.1917e-04, 1.6970e-04,  ..., 5.9315e-05,\n",
            "           1.9313e-04, 7.3389e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.6262e-02, 1.9966e-02, 2.4952e-04,  ..., 5.7092e-03,\n",
            "           1.6685e-03, 1.4495e-02]],\n",
            "\n",
            "         [[3.0931e-03, 9.4643e-03, 4.2403e-05,  ..., 1.4906e-05,\n",
            "           4.3261e-05, 2.1986e-02]],\n",
            "\n",
            "         [[4.9123e-04, 5.2855e-03, 8.1884e-05,  ..., 1.1442e-05,\n",
            "           5.6166e-05, 1.3468e-02]]]], grad_fn=<ViewBackward0>), tensor([[[[2.3494e-05, 6.9320e-04, 5.8791e-05,  ..., 3.1664e-05,\n",
            "           1.6119e-04, 4.2627e-04]],\n",
            "\n",
            "         [[2.1020e-04, 1.1975e-04, 1.0450e-05,  ..., 2.1762e-05,\n",
            "           5.7690e-06, 2.1866e-04]],\n",
            "\n",
            "         [[3.2796e-05, 2.7628e-04, 4.8871e-05,  ..., 1.0237e-04,\n",
            "           1.0512e-04, 4.9642e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[4.7411e-04, 1.9551e-03, 1.5387e-04,  ..., 8.4011e-05,\n",
            "           1.7270e-04, 2.4842e-03]],\n",
            "\n",
            "         [[1.2790e-04, 1.9061e-03, 6.0392e-04,  ..., 2.9119e-05,\n",
            "           1.3450e-04, 2.6598e-04]],\n",
            "\n",
            "         [[8.6490e-04, 2.5404e-04, 1.3593e-06,  ..., 2.5585e-05,\n",
            "           3.5204e-04, 2.0611e-04]]]], grad_fn=<ViewBackward0>), tensor([[[[8.0167e-04, 5.9899e-04, 3.7676e-04,  ..., 5.1062e-05,\n",
            "           1.9913e-04, 8.7408e-03]],\n",
            "\n",
            "         [[1.7890e-04, 2.7188e-04, 1.6482e-04,  ..., 7.1504e-05,\n",
            "           2.3482e-04, 1.7239e-04]],\n",
            "\n",
            "         [[1.1029e-03, 9.2042e-04, 2.2397e-04,  ..., 1.9132e-04,\n",
            "           9.4864e-04, 1.1782e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[7.0652e-05, 4.2598e-04, 4.0444e-05,  ..., 2.1822e-05,\n",
            "           1.3976e-04, 6.4778e-04]],\n",
            "\n",
            "         [[2.6705e-03, 2.7954e-04, 4.2105e-04,  ..., 7.7506e-05,\n",
            "           1.2233e-04, 7.8879e-03]],\n",
            "\n",
            "         [[1.4866e-03, 5.0129e-04, 8.0539e-05,  ..., 7.3270e-05,\n",
            "           8.7553e-04, 7.9069e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[1.1185e-03, 3.3926e-04, 1.3705e-03,  ..., 6.7367e-05,\n",
            "           1.0743e-05, 1.0831e-02]],\n",
            "\n",
            "         [[9.0737e-04, 1.1869e-03, 2.2857e-04,  ..., 2.0899e-04,\n",
            "           2.0358e-03, 9.9173e-04]],\n",
            "\n",
            "         [[1.4028e-03, 2.4315e-03, 9.5993e-04,  ..., 9.9927e-05,\n",
            "           1.2020e-04, 3.5753e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.0661e-03, 2.0459e-03, 4.8838e-04,  ..., 6.8850e-05,\n",
            "           1.9443e-04, 6.9714e-03]],\n",
            "\n",
            "         [[4.4764e-03, 4.3076e-03, 2.0332e-03,  ..., 5.5772e-05,\n",
            "           1.9588e-04, 1.1609e-03]],\n",
            "\n",
            "         [[4.0765e-03, 2.2055e-03, 5.6319e-04,  ..., 1.5127e-04,\n",
            "           3.6370e-05, 1.1499e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[2.1352e-04, 1.2832e-03, 8.6485e-04,  ..., 6.1627e-05,\n",
            "           2.7169e-04, 8.7604e-05]],\n",
            "\n",
            "         [[1.2792e-03, 1.2045e-03, 1.6426e-03,  ..., 6.0533e-05,\n",
            "           1.6698e-04, 2.3472e-02]],\n",
            "\n",
            "         [[4.6873e-04, 1.5442e-04, 1.2817e-04,  ..., 2.2252e-04,\n",
            "           8.7647e-05, 3.0548e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[3.9785e-04, 1.4997e-03, 2.1721e-04,  ..., 2.9355e-04,\n",
            "           8.9440e-04, 2.3129e-03]],\n",
            "\n",
            "         [[9.0412e-04, 1.0684e-03, 2.8792e-04,  ..., 8.3409e-04,\n",
            "           1.8045e-05, 1.3961e-03]],\n",
            "\n",
            "         [[3.0531e-04, 1.4774e-04, 3.9715e-05,  ..., 9.7830e-06,\n",
            "           8.3539e-05, 8.8231e-06]]]], grad_fn=<ViewBackward0>), tensor([[[[5.8579e-03, 8.4869e-03, 2.4337e-03,  ..., 4.5392e-04,\n",
            "           6.7150e-03, 1.1009e-01]],\n",
            "\n",
            "         [[4.4229e-04, 2.1855e-03, 9.2036e-04,  ..., 3.1020e-04,\n",
            "           1.9132e-03, 7.7098e-04]],\n",
            "\n",
            "         [[5.8831e-04, 3.1311e-04, 1.3839e-04,  ..., 1.5608e-04,\n",
            "           4.1103e-04, 1.8685e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[7.8804e-04, 8.7801e-04, 1.0736e-04,  ..., 2.0908e-04,\n",
            "           1.0576e-04, 6.4343e-03]],\n",
            "\n",
            "         [[2.2262e-03, 8.9850e-04, 5.1839e-04,  ..., 1.7654e-03,\n",
            "           4.2977e-03, 1.6120e-03]],\n",
            "\n",
            "         [[3.5545e-03, 4.4199e-04, 2.2860e-04,  ..., 1.0958e-05,\n",
            "           7.2223e-05, 4.0798e-04]]]], grad_fn=<ViewBackward0>), tensor([[[[9.9121e-03, 2.8299e-03, 2.0870e-03,  ..., 6.3525e-04,\n",
            "           1.9150e-03, 3.0456e-03]],\n",
            "\n",
            "         [[5.9326e-04, 3.7528e-04, 1.2907e-04,  ..., 1.8059e-04,\n",
            "           8.5701e-04, 1.7651e-03]],\n",
            "\n",
            "         [[9.7725e-03, 7.1477e-03, 1.3591e-04,  ..., 8.8680e-03,\n",
            "           2.1726e-04, 1.5344e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[3.3891e-03, 4.1701e-03, 1.4573e-03,  ..., 4.8174e-04,\n",
            "           3.0925e-03, 3.9961e-03]],\n",
            "\n",
            "         [[4.6768e-04, 1.1818e-03, 3.8637e-04,  ..., 5.7758e-05,\n",
            "           3.5159e-03, 2.7605e-07]],\n",
            "\n",
            "         [[1.1247e-03, 8.1939e-04, 5.0089e-04,  ..., 6.0903e-04,\n",
            "           4.4877e-03, 3.6970e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[2.4079e-03, 7.1381e-04, 2.7099e-04,  ..., 1.6636e-03,\n",
            "           4.6838e-04, 5.4370e-04]],\n",
            "\n",
            "         [[1.8134e-03, 3.1643e-03, 2.1399e-04,  ..., 7.4242e-04,\n",
            "           3.8832e-04, 1.2122e-02]],\n",
            "\n",
            "         [[3.8607e-03, 9.9389e-04, 1.6963e-04,  ..., 2.0523e-04,\n",
            "           2.3375e-03, 8.3944e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[4.5411e-04, 2.4852e-04, 4.2982e-05,  ..., 6.7119e-05,\n",
            "           1.1044e-03, 1.3732e-02]],\n",
            "\n",
            "         [[1.5204e-03, 1.4298e-02, 3.0178e-04,  ..., 1.2679e-03,\n",
            "           1.0217e-02, 2.4543e-03]],\n",
            "\n",
            "         [[1.7910e-03, 7.0723e-03, 8.2727e-05,  ..., 7.2505e-04,\n",
            "           2.4411e-03, 1.0731e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[2.2243e-03, 2.8769e-03, 1.4266e-03,  ..., 2.9878e-03,\n",
            "           2.1053e-03, 3.5627e-03]],\n",
            "\n",
            "         [[4.6645e-03, 1.0397e-03, 3.6108e-05,  ..., 4.9981e-04,\n",
            "           1.5271e-04, 1.8802e-03]],\n",
            "\n",
            "         [[1.2242e-03, 1.8132e-03, 7.4731e-04,  ..., 3.0235e-03,\n",
            "           8.0381e-04, 1.0992e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[4.9374e-03, 3.0715e-03, 4.9923e-04,  ..., 1.1885e-03,\n",
            "           2.7796e-03, 1.0311e-02]],\n",
            "\n",
            "         [[4.5774e-03, 8.4414e-04, 2.2707e-04,  ..., 9.4698e-04,\n",
            "           4.4197e-04, 1.6501e-03]],\n",
            "\n",
            "         [[1.1400e-02, 2.7552e-03, 1.1427e-03,  ..., 9.2756e-03,\n",
            "           1.2695e-04, 4.3021e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[6.1283e-04, 1.6909e-03, 2.7508e-04,  ..., 6.1479e-04,\n",
            "           7.2835e-04, 2.9073e-03]],\n",
            "\n",
            "         [[1.5482e-03, 1.4921e-03, 1.6417e-04,  ..., 5.1664e-04,\n",
            "           6.2880e-04, 7.2087e-03]],\n",
            "\n",
            "         [[5.5870e-03, 1.0869e-03, 2.8790e-05,  ..., 5.7336e-04,\n",
            "           1.0276e-04, 1.8406e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[1.9323e-03, 3.7177e-04, 2.9855e-04,  ..., 3.9741e-03,\n",
            "           1.2225e-03, 5.9533e-03]],\n",
            "\n",
            "         [[1.7025e-03, 4.2367e-04, 6.9627e-05,  ..., 2.2228e-03,\n",
            "           3.8322e-04, 5.0830e-03]],\n",
            "\n",
            "         [[2.1044e-03, 7.4123e-04, 5.0905e-04,  ..., 6.2199e-04,\n",
            "           7.6170e-04, 5.7297e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[1.0595e-02, 2.3185e-03, 1.9750e-04,  ..., 2.0748e-03,\n",
            "           1.2615e-03, 7.6531e-03]],\n",
            "\n",
            "         [[1.0172e-03, 1.3111e-03, 1.0902e-04,  ..., 3.3965e-03,\n",
            "           6.0322e-04, 3.4098e-03]],\n",
            "\n",
            "         [[6.2297e-04, 3.3533e-03, 2.8017e-03,  ..., 2.3326e-03,\n",
            "           1.6164e-03, 1.5313e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[7.2729e-04, 1.0751e-04, 9.0183e-05,  ..., 1.4217e-03,\n",
            "           3.7578e-04, 4.8856e-03]],\n",
            "\n",
            "         [[9.4562e-04, 3.1779e-04, 6.0350e-04,  ..., 8.0038e-04,\n",
            "           1.8074e-04, 9.5304e-04]],\n",
            "\n",
            "         [[1.6898e-03, 2.2544e-03, 1.7340e-04,  ..., 3.1988e-03,\n",
            "           5.5077e-04, 4.7409e-03]]]], grad_fn=<ViewBackward0>), tensor([[[[1.5669e-03, 2.2757e-04, 1.8637e-04,  ..., 1.2336e-03,\n",
            "           1.6057e-03, 1.2935e-03]],\n",
            "\n",
            "         [[6.6909e-04, 8.9953e-04, 2.3029e-04,  ..., 1.5610e-03,\n",
            "           1.2649e-03, 1.3896e-03]],\n",
            "\n",
            "         [[8.5102e-03, 4.0913e-04, 1.1635e-04,  ..., 1.9042e-03,\n",
            "           6.3691e-04, 1.8207e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[2.0191e-02, 1.1245e-03, 1.9074e-04,  ..., 1.1284e-03,\n",
            "           1.7313e-03, 1.6390e-03]],\n",
            "\n",
            "         [[1.8390e-03, 1.4039e-03, 5.3234e-04,  ..., 4.5272e-05,\n",
            "           7.0508e-03, 1.0583e-02]],\n",
            "\n",
            "         [[1.8287e-03, 2.2416e-04, 4.5569e-05,  ..., 8.7588e-04,\n",
            "           1.2363e-03, 4.0354e-03]]]], grad_fn=<ViewBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary Distribution:\")\n",
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtc5Qpuc1cdQ",
        "outputId": "b10ce01d-3504-4f68-c5c1-9c1604e23fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Distribution:\n",
            "tensor([[[-0.4234, 14.2356,  0.5334,  ..., -7.1022, -4.2433, -9.4791]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context vector $h^*_t$ is the dot product of multi-headed encoder-decoder cross-attention (sum of 16 heads of $1\\times189$ vector) and encoder last hidden state ($189\\times1024 vector$):"
      ],
      "metadata": {
        "id": "Gh3PAwUCv_-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.cross_attentions[-1].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pApu5GC991HT",
        "outputId": "da8382cc-0201-4c75-ee9e-483eb121d4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 1, 189])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.encoder_last_hidden_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAoao5J0rk5K",
        "outputId": "8e218f56-dafc-4943-923e-8ea6d3ddc60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.2002, -0.1047, -0.0696,  ...,  0.1101, -0.0118,  0.0643],\n",
            "         [-0.1280, -0.0091, -0.1026,  ..., -0.1198,  0.0205,  0.1092],\n",
            "         [ 0.0200, -0.0108, -0.1908,  ..., -0.2198, -0.0190,  0.0378],\n",
            "         ...,\n",
            "         [-0.0116,  0.2254, -0.2567,  ...,  0.0488, -0.1272, -0.0536],\n",
            "         [ 0.1791,  0.0673, -0.2450,  ...,  0.2363, -0.1964,  0.0312],\n",
            "         [ 0.2136, -0.1332, -0.0578,  ..., -0.0558, -0.1657, -0.1278]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.encoder_last_hidden_state.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hIErpIs5GXQ",
        "outputId": "208554e5-9348-4a9e-f917-583179877793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 189, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decoder state $s_t$ is a  $1\\times1024$ vector:"
      ],
      "metadata": {
        "id": "ja1zgEeXxgte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.decoder_hidden_states[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSgzzsaDrgeu",
        "outputId": "ba1ab7e6-d5d4-4fc4-b7e6-a70e26af6eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.1768, -0.0050,  0.2316,  ..., -0.1031, -0.0421, -0.0165]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.decoder_hidden_states[-1].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6uPnyRb6OxU",
        "outputId": "7eefcef7-7237-44ba-e01a-c9953bc92bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decoder input $x_t$ is a $1\\times1024$ vector, and would be updated for each decoder timestep $t$:"
      ],
      "metadata": {
        "id": "PAMep9yVxxQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.decoder_hidden_states[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nud6YGt1rcUa",
        "outputId": "7c5826eb-4e9e-46d8-a9a4-e40a80495799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.8576e+01, -7.7758e-03,  5.4886e+01,  ..., -3.9867e+00,\n",
            "           1.2295e+01, -2.6963e+00]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.decoder_hidden_states[0].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xes7Gyro58cg",
        "outputId": "1f928c10-25f1-4143-ac1b-557acd32a51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The $p_{gen}$ can calculated from a sigmoid function applied on a linear equation of $p_{gen}=σ(w_h^T*h_t^*+w_s^T*s_t+w_x^T*x_t+b_ptr )$, resulting in a vector size of $1\\times96,103$:"
      ],
      "metadata": {
        "id": "ynMcSDl7ySk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin = torch.nn.Linear(1024, 1024)\n",
        "sig = torch.sigmoid(1024, 96103)\n",
        "linear_h = torch.nn.linear(torch.dot(outputs.cross_attentions[-1],outputs.encoder_last_hidden_state))\n",
        "lienar_s = torch.nn.linear(outputs.decoder_hidden_states[-1])\n",
        "lienar_x = torch.nn.linear(outputs.decoder_hidden_states[0])\n",
        "p_gen = sig(lin(torch.cat(linear_h, linear_s, linear_x))"
      ],
      "metadata": {
        "id": "40WHOil0ySPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PEGASUS transformer has a probability output given a vector size of $1\\times96,103$:"
      ],
      "metadata": {
        "id": "cMuGBLWNx700"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.logits.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ENy6gZk93LX",
        "outputId": "8eb38c93-23c8-41e2-dfde-9788d05b5063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 96103])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final distribution can be calculated given the decoder input, $p_{gen}$, vocabulary distribution (logits output from pretrained transformer model) context vector (attention distribution):"
      ],
      "metadata": {
        "id": "l3B404AMyQf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _calc_final_dist(self, x, p_gens, vocab_dists, attn_dists):\n",
        "    \"\"\"Calculate the final distribution, for the pointer-generator model\n",
        "    Args:\n",
        "      x: encoder input which contain oov number\n",
        "      p_gens: the generation probability, choose vocab from article or vocab\n",
        "      vocab_dists: The vocabulary distributions\n",
        "      attn_dists: The attention distributions\n",
        "    Returns:\n",
        "      final_dists: The final distributions\n",
        "    \"\"\"\n",
        "    with tf.variable_scope('final_distribution', reuse=tf.AUTO_REUSE):\n",
        "        # Multiply vocab dists by p_gen and attention dists by (1-p_gen)\n",
        "        vocab_dists = p_gens * vocab_dists\n",
        "        attn_dists = (1-p_gens) * attn_dists\n",
        "        batch_size = tf.shape(attn_dists)[0]\n",
        "        dec_t = tf.shape(attn_dists)[1]\n",
        "        attn_len = tf.shape(attn_dists)[2]\n",
        "        dec = tf.range(0, limit=dec_t) # [dec]\n",
        "        dec = tf.expand_dims(dec, axis=-1) # [dec, 1]\n",
        "        dec = tf.tile(dec, [1, attn_len]) # [dec, atten_len]\n",
        "        dec = tf.expand_dims(dec, axis=0) # [1, dec, atten_len]\n",
        "        dec = tf.tile(dec, [batch_size, 1, 1]) # [batch_size, dec, atten_len]\n",
        "        x = tf.expand_dims(x, axis=1) # [batch_size, 1, atten_len]\n",
        "        x = tf.tile(x, [1, dec_t, 1]) # [batch_size, dec, atten_len]\n",
        "        x = tf.stack([dec, x], axis=3)\n",
        "        attn_dists_projected = tf.map_fn(fn=lambda y: tf.scatter_nd(y[0], y[1], [dec_t, self.hp.vocab_size]),\n",
        "                                         elems=(x, attn_dists), dtype=tf.float32)\n",
        "        final_dists = attn_dists_projected + vocab_dists\n",
        "    return final_dists"
      ],
      "metadata": {
        "id": "IeO1mt8p_GAj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}